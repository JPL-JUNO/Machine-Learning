\chapter{Combining Different Models for Ensemble Learning\label{Ch07}}
\section{Learning with ensembles}
The goal of ensemble methods is to combine different classifiers into a meta-classifier that has better generalization performance than each individual classifier alone.
\section{Bagging – building an ensemble of classifiers from bootstrap samples}
Instead of using the same training dataset to fit the individual classifiers in the ensemble, we draw bootstrap samples (random samples with replacement) from the initial training dataset, which is why bagging is also known as \textit{bootstrap aggregating}.

The concept of bagging is summarized in \autoref{fig7-6}:
\figures{fig7-6}{The concept of bagging}
\subsection{Bagging in a nutshell}
In fact, random forests are a special case of bagging where we also use random feature subsets when fitting the individual decision trees.

In practice, more complex classification tasks and a dataset's high dimensionality can easily lead to overfitting in single decision trees, and this is where the bagging algorithm can really play to its strengths. Finally, we must note that the bagging algorithm can be an effective approach to reducing the variance of a model. However, bagging is ineffective in reducing model bias, that is, models that are too simple to capture the trends in the data well. This is why we want to perform bagging on an ensemble of classifiers with low bias, for example, unpruned decision trees.
\section{Leveraging weak learners via adaptive boosting}
We will discuss \textbf{boosting}, with a special focus on its most common implementation: \textbf{Adaptive Boosting} (AdaBoost).

In boosting, the ensemble consists of very simple base classifiers, also often referred to as weak learners, which often only have a slight performance advantage over random guessing—a typical example of a weak learner is a decision tree stump. The key concept behind boosting is to focus on training examples that are hard to classify, that is, to let the weak learners subsequently learn from misclassified training examples to improve the performance of the ensemble.
\subsection{How adaptive boosting works}
In contrast to bagging, the initial formulation of the boosting algorithm uses random subsets of training examples drawn from the training dataset without replacement; the original boosting procedure can be summarized in the following four key steps:
\begin{enumerate}
    \item Draw a random subset (sample) of training examples, $d_1$, without replacement from the training dataset, $D$, to train a weak learner, $C_1$.
    \item Draw a second random training subset, $d_2$, without replacement from the training dataset and add 50 percent of the examples that were previously misclassified to train a weak learner, $C_2$.
    \item Find the training examples, $d_3$, in the training dataset, $D$, which $C_1$ and $C_2$ disagree upon, to train a third weak learner, $C_3$.
    \item Combine the weak learners $C_1$, $C_2$, and $C_3$ via majority voting.
\end{enumerate}

As discussed by Leo Breiman, boosting can lead to a decrease in bias as well as variance compared to bagging models. In practice, however, boosting algorithms such as AdaBoost are also known for their high variance, that is, the tendency to overfit the training data.

\figures{fig7-9}{The concept of AdaBoost to improve weak learners}

\begin{algorithm}
    \Begin{
        initialization, Set the weight vector, $\textbf{w}$, to uniform weights, where $\sum_{i}w_i=1$\;
        \For{$j\rightarrow 1$\KwTo $m$}{
            Train a weighted weak learner: $C_j = train(\textbf{X}, \textbf{y}, \textbf{w})$\;
            Predict class labels: $\hat{y} = predict(C_j, \textbf{X})$\;
            Compute the weighted error rate: $\epsilon=\textbf{W}\cdot(\hat{\textbf{y}}\neq \textbf{y})$\;
            Compute the coefficient:$\alpha_j= 0.5\log\frac{1-\epsilon}{\epsilon}$\;
            Update the weights: $\textbf{w}\leftarrow\textbf{w}\times\exp(-\alpha_j\times\hat{\textbf{y}}\times\textbf{y})$\;
            Normalize the weights to sum to 1:$\textbf{w}\leftarrow\textbf{w}/\sum_{i}w_i$\;
        }
        Compute the final prediction: $\hat{\textbf{y}}=\left(\sum_{j=1}^{m}\left(\alpha_j\times predict(C_j, \textbf{X})\right)\right)$\;
    }
    \caption{AdaBoost algorithm}
\end{algorithm}
\section{Gradient boosting – training an ensemble based on loss gradients}
\subsection{Outlining the general gradient boosting algorithm}
\begin{algorithm}
    \Begin{
    Initialize a model to return a constant prediction value. For this, we use a decision tree root node; that is, a decision tree with a single leaf node. We denote the value returned by the tree as $\hat{y}$ , and we find this value by minimizing a differentiable loss function $L$ that we will define later:
    $$F_0(x)=\argmin\limits_{\hat{y}}\sum_{i=1}^{n}L(y_i,\hat{y})$$
    Here, $n$ refers to the $n$ training examples in our dataset\;
    \ForEach{m=1,\dots, M}{
    Compute the difference between a predicted value $F(x_i)=\hat{y_i}$and the class label $y_i$. This value is sometimes called the pseudo-response or pseudo-residual. More formally, we can write this pseudo-residual as the negative gradient of the loss function with respect to the predicted values:
    $$r_{im}=-\left[\frac{\partial L(y_i,F(x_i))}{\partial F(x_i)}\right]_{F(x)=F_{m-1}(x)},~i=1, \dots, n$$
    Note that in the notation above $F(x)$ is the prediction of the previous tree, $F_{m–1}(x)$\;
    Fit a tree to the pseudo-residuals rim. We use the notation $R_{jm}$to denote the $j = 1 ... Jm$ leaf nodes of the resulting tree in iteration $m$.
    For each leaf node Rjm, we compute the following output value:
    $$\gamma_{jm}=\argmin\limits_\gamma\sum_{x_i\in R_{jm}}L(y_i,F_{m-1}(x_i)+\gamma)$$
    At this point, we can already note that leaf nodes $R_{jm}$ may contain more than one training example, hence the summation\;
    Update the model by adding the output values $\gamma_m$ to the previous tree:
    $$F_m(x)=F_{m-1}(x)+\eta\gamma_m$$
    However, instead of adding the full predicted values of the current tree $\gamma_m$ to the previous tree $F_{m-1}$ , we scale $\gamma_m$ by a learning rate $\eta$ , which is typically a small value between 0.01 and 1. In other words, we update the model incrementally by taking small steps, which helps avoid overfitting.
    }
    }
    \caption{The general outline of the gradient boosting algorithm.}
\end{algorithm}